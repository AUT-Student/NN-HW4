{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_HW4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JBwnf_FrU_Mj",
        "XjaZf_08RENI",
        "_GS7LTfZRvuO"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMJ0982EfrIrbC8lA3Ll+Bt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AUT-Student/NN-HW4/blob/main/NN_HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "ntmFFP5_GuCa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JeslGkMkeFT2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Conv2D, Flatten, AveragePooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.applications.inception_v3 import InceptionV3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "jeWm1guJG39O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tfds.load('beans', split=[\"test\", \"train\", \"validation\"], shuffle_files=True)"
      ],
      "metadata": {
        "id": "MaC1owEmG3LU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds, info = tfds.load('beans', with_info=True)\n",
        "\n",
        "print(info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNpD1LqdNAWy",
        "outputId": "ec531b53-62ac-4acc-a24e-55ec8ede692c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='beans',\n",
            "    version=0.1.0,\n",
            "    description='Beans is a dataset of images of beans taken in the field using smartphone\n",
            "cameras. It consists of 3 classes: 2 disease classes and the healthy class.\n",
            "Diseases depicted include Angular Leaf Spot and Bean Rust. Data was annotated\n",
            "by experts from the National Crops Resources Research Institute (NaCRRI) in\n",
            "Uganda and collected by the Makerere AI research lab.',\n",
            "    homepage='https://github.com/AI-Lab-Makerere/ibean/',\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(500, 500, 3), dtype=tf.uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
            "    }),\n",
            "    total_num_examples=1295,\n",
            "    splits={\n",
            "        'test': 128,\n",
            "        'train': 1034,\n",
            "        'validation': 133,\n",
            "    },\n",
            "    supervised_keys=('image', 'label'),\n",
            "    citation=\"\"\"@ONLINE {beansdata,\n",
            "        author=\"Makerere AI Lab\",\n",
            "        title=\"Bean disease dataset\",\n",
            "        month=\"January\",\n",
            "        year=\"2020\",\n",
            "        url=\"https://github.com/AI-Lab-Makerere/ibean/\"\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = tfds.load(name=\"beans\", split=\"train\", batch_size=-1) \n",
        "data_valid = tfds.load(name=\"beans\", split=\"validation\", batch_size=-1)\n",
        "data_test = tfds.load(name=\"beans\", split=\"test\", batch_size=-1)\n",
        "\n",
        "data_train = tfds.as_numpy(data_train)\n",
        "data_valid = tfds.as_numpy(data_valid)\n",
        "data_test = tfds.as_numpy(data_test)\n",
        "\n",
        "x_train, y_train = data_train[\"image\"], data_train[\"label\"]\n",
        "x_valid, y_valid = data_valid[\"image\"], data_valid[\"label\"]\n",
        "x_test, y_test = data_test[\"image\"], data_test[\"label\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbo4rhjYceR_",
        "outputId": "fbc81335-bd19-464a-8761-fc005625e2a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py:598: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.get_single_element()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py:598: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.get_single_element()`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chXyQ76FeNcf",
        "outputId": "8630410e-6d05-4177-e11c-9a356e9cd4ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1034, 500, 500, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LeNet"
      ],
      "metadata": {
        "id": "oMgHR0dUN6Jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Vw357HDMuxMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(keras.Model):\n",
        "  def __init__(self, kernel_size=5, kernel_numbers = [6, 16, 120],\n",
        "               dropout_enable=False, l1_enable=False, l2_enable=False):\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = Sequential()\n",
        "\n",
        "    self.model.add(Input((500, 500, 3,), name=\"Input\"))\n",
        "    \n",
        "    conv2D = Conv2D(kernel_numbers[0], kernel_size=kernel_size, strides=4,\n",
        "                    activation=\"tanh\", name=\"Conv1\", padding=\"same\")\n",
        "\n",
        "    if l1_enable:\n",
        "      conv2D.kernel_regularizer = l1()\n",
        "    elif l2_enable:\n",
        "      conv2D.kernel_regularizer = l2()\n",
        "    self.model.add(conv2D)\n",
        "\n",
        "    if dropout_enable:\n",
        "      self.model.add(Dropout(rate=0.5, name=\"Drop1\"))\n",
        "    \n",
        "    self.model.add(AveragePooling2D(pool_size=3, name=\"Pool1\"))\n",
        "    \n",
        "    conv2D = Conv2D(kernel_numbers[1], kernel_size=kernel_size, strides=4,\n",
        "                    activation=\"tanh\", name=\"Conv2\", padding=\"same\")\n",
        "\n",
        "    if l1_enable:\n",
        "      conv2D.kernel_regularizer = l1()\n",
        "    elif l2_enable:\n",
        "      conv2D.kernel_regularizer = l2()\n",
        "    self.model.add(conv2D)\n",
        "    \n",
        "    if dropout_enable:\n",
        "      self.model.add(Dropout(rate=0.5, name=\"Drop2\"))\n",
        "\n",
        "    self.model.add(AveragePooling2D(pool_size=3, name=\"Pool2\"))\n",
        "    conv2D = Conv2D(kernel_numbers[2], kernel_size=kernel_size, strides=3,\n",
        "                    activation=\"tanh\", name=\"Conv3\", padding=\"same\")\n",
        "\n",
        "    if l1_enable:\n",
        "      conv2D.kernel_regularizer = l1()\n",
        "    elif l2_enable:\n",
        "      conv2D.kernel_regularizer = l2()\n",
        "    self.model.add(conv2D)\n",
        "    \n",
        "    if dropout_enable:\n",
        "      self.model.add(Dropout(rate=0.5, name=\"Drop3\"))\n",
        "    \n",
        "    self.model.add(Flatten(name=\"Flat\"))\n",
        "    self.model.add(Dense(84, activation=\"tanh\", name=\"Dense\"))\n",
        "    self.model.add(Dense(3, activation=\"softmax\", name=\"Output\"))\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self.model.call(inputs)"
      ],
      "metadata": {
        "id": "SEoZ7paXN7O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularization Effect"
      ],
      "metadata": {
        "id": "JBwnf_FrU_Mj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without Regularization"
      ],
      "metadata": {
        "id": "Z81OS4r8P6GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenet = LeNet(kernel_size=5)\n",
        "es_callback = EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True)\n",
        "lenet.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "odplXd6VPd_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), epochs=30, callbacks=[es_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-Va3EfAZ1V3",
        "outputId": "03f8df96-922e-4ffe-8663-0498880d56c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "33/33 [==============================] - 14s 404ms/step - loss: 1.0125 - accuracy: 0.4797 - val_loss: 0.8875 - val_accuracy: 0.6015\n",
            "Epoch 2/30\n",
            "33/33 [==============================] - 14s 439ms/step - loss: 0.9227 - accuracy: 0.5706 - val_loss: 0.8935 - val_accuracy: 0.5789\n",
            "Epoch 3/30\n",
            "33/33 [==============================] - 14s 425ms/step - loss: 0.8902 - accuracy: 0.5986 - val_loss: 0.8651 - val_accuracy: 0.6466\n",
            "Epoch 4/30\n",
            "33/33 [==============================] - 14s 420ms/step - loss: 0.8463 - accuracy: 0.6228 - val_loss: 0.8401 - val_accuracy: 0.5940\n",
            "Epoch 5/30\n",
            "33/33 [==============================] - 14s 416ms/step - loss: 0.8279 - accuracy: 0.6132 - val_loss: 0.9516 - val_accuracy: 0.5338\n",
            "Epoch 6/30\n",
            "33/33 [==============================] - 13s 381ms/step - loss: 0.8493 - accuracy: 0.6025 - val_loss: 0.8659 - val_accuracy: 0.5940\n",
            "Epoch 7/30\n",
            "33/33 [==============================] - 13s 388ms/step - loss: 0.8036 - accuracy: 0.6422 - val_loss: 0.8013 - val_accuracy: 0.6090\n",
            "Epoch 8/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 0.7645 - accuracy: 0.6625 - val_loss: 0.7399 - val_accuracy: 0.6692\n",
            "Epoch 9/30\n",
            "33/33 [==============================] - 13s 381ms/step - loss: 0.7247 - accuracy: 0.6915 - val_loss: 0.7682 - val_accuracy: 0.6692\n",
            "Epoch 10/30\n",
            "33/33 [==============================] - 13s 381ms/step - loss: 0.7328 - accuracy: 0.6760 - val_loss: 0.7254 - val_accuracy: 0.7068\n",
            "Epoch 11/30\n",
            "33/33 [==============================] - 13s 386ms/step - loss: 0.7027 - accuracy: 0.6886 - val_loss: 0.7274 - val_accuracy: 0.6541\n",
            "Epoch 12/30\n",
            "33/33 [==============================] - 13s 382ms/step - loss: 0.6854 - accuracy: 0.7070 - val_loss: 0.7032 - val_accuracy: 0.7143\n",
            "Epoch 13/30\n",
            "33/33 [==============================] - 13s 381ms/step - loss: 0.6907 - accuracy: 0.6925 - val_loss: 0.7131 - val_accuracy: 0.6692\n",
            "Epoch 14/30\n",
            "33/33 [==============================] - 12s 379ms/step - loss: 0.6953 - accuracy: 0.6992 - val_loss: 0.7177 - val_accuracy: 0.6917\n",
            "Epoch 15/30\n",
            "33/33 [==============================] - 13s 403ms/step - loss: 0.6998 - accuracy: 0.6886 - val_loss: 0.7654 - val_accuracy: 0.6992\n",
            "Epoch 16/30\n",
            "33/33 [==============================] - 13s 379ms/step - loss: 0.6981 - accuracy: 0.6828 - val_loss: 0.7148 - val_accuracy: 0.6391\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f407bdfe990>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lenet.evaluate(x=x_train, y=y_train)\n",
        "lenet.evaluate(x=x_valid, y=y_valid)\n",
        "lenet.evaluate(x=x_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZhHoh6rhF7l",
        "outputId": "10b0144b-aee7-4cac-f988-e6245c578a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 7s 219ms/step - loss: 0.6673 - accuracy: 0.7244\n",
            "5/5 [==============================] - 1s 178ms/step - loss: 0.7032 - accuracy: 0.7143\n",
            "4/4 [==============================] - 1s 213ms/step - loss: 0.6803 - accuracy: 0.6875\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6803126931190491, 0.6875]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout Regularization"
      ],
      "metadata": {
        "id": "mJYa7WcgQAUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenet = LeNet(dropout_enable=True)\n",
        "es_callback = EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True)\n",
        "lenet.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "dzGf0hbPP35t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), epochs=30, callbacks=[es_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjIxbL_4QIyW",
        "outputId": "826b2674-7626-4eef-9023-e631efbc07c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "33/33 [==============================] - 15s 416ms/step - loss: 1.0481 - accuracy: 0.4429 - val_loss: 0.9382 - val_accuracy: 0.5414\n",
            "Epoch 2/30\n",
            "33/33 [==============================] - 14s 410ms/step - loss: 0.9198 - accuracy: 0.5629 - val_loss: 0.8080 - val_accuracy: 0.6617\n",
            "Epoch 3/30\n",
            "33/33 [==============================] - 14s 424ms/step - loss: 0.8493 - accuracy: 0.6141 - val_loss: 0.7799 - val_accuracy: 0.6617\n",
            "Epoch 4/30\n",
            "33/33 [==============================] - 15s 471ms/step - loss: 0.8576 - accuracy: 0.6151 - val_loss: 0.7649 - val_accuracy: 0.6541\n",
            "Epoch 5/30\n",
            "33/33 [==============================] - 15s 446ms/step - loss: 0.8101 - accuracy: 0.6422 - val_loss: 0.8076 - val_accuracy: 0.5940\n",
            "Epoch 6/30\n",
            "33/33 [==============================] - 16s 478ms/step - loss: 0.7936 - accuracy: 0.6509 - val_loss: 0.7112 - val_accuracy: 0.7218\n",
            "Epoch 7/30\n",
            "33/33 [==============================] - 15s 454ms/step - loss: 0.7518 - accuracy: 0.6683 - val_loss: 0.7306 - val_accuracy: 0.6391\n",
            "Epoch 8/30\n",
            "33/33 [==============================] - 17s 507ms/step - loss: 0.7756 - accuracy: 0.6480 - val_loss: 0.7585 - val_accuracy: 0.5940\n",
            "Epoch 9/30\n",
            "33/33 [==============================] - 14s 415ms/step - loss: 0.7624 - accuracy: 0.6692 - val_loss: 0.7086 - val_accuracy: 0.6767\n",
            "Epoch 10/30\n",
            "33/33 [==============================] - 14s 421ms/step - loss: 0.7517 - accuracy: 0.6760 - val_loss: 0.6774 - val_accuracy: 0.6917\n",
            "Epoch 11/30\n",
            "33/33 [==============================] - 14s 433ms/step - loss: 0.7248 - accuracy: 0.6692 - val_loss: 0.6617 - val_accuracy: 0.7218\n",
            "Epoch 12/30\n",
            "33/33 [==============================] - 16s 472ms/step - loss: 0.7463 - accuracy: 0.6731 - val_loss: 0.6541 - val_accuracy: 0.7444\n",
            "Epoch 13/30\n",
            "33/33 [==============================] - 15s 468ms/step - loss: 0.7590 - accuracy: 0.6422 - val_loss: 0.8213 - val_accuracy: 0.6391\n",
            "Epoch 14/30\n",
            "33/33 [==============================] - 15s 469ms/step - loss: 0.7369 - accuracy: 0.6702 - val_loss: 0.6625 - val_accuracy: 0.6692\n",
            "Epoch 15/30\n",
            "33/33 [==============================] - 15s 443ms/step - loss: 0.7227 - accuracy: 0.6779 - val_loss: 0.7247 - val_accuracy: 0.6015\n",
            "Epoch 16/30\n",
            "33/33 [==============================] - 14s 424ms/step - loss: 0.6969 - accuracy: 0.6905 - val_loss: 0.6294 - val_accuracy: 0.7143\n",
            "Epoch 17/30\n",
            "33/33 [==============================] - 15s 459ms/step - loss: 0.6686 - accuracy: 0.7108 - val_loss: 0.6247 - val_accuracy: 0.7594\n",
            "Epoch 18/30\n",
            "33/33 [==============================] - 15s 459ms/step - loss: 0.7021 - accuracy: 0.6973 - val_loss: 0.6256 - val_accuracy: 0.7218\n",
            "Epoch 19/30\n",
            "33/33 [==============================] - 14s 430ms/step - loss: 0.6788 - accuracy: 0.7041 - val_loss: 0.6222 - val_accuracy: 0.7368\n",
            "Epoch 20/30\n",
            "33/33 [==============================] - 14s 416ms/step - loss: 0.6871 - accuracy: 0.6983 - val_loss: 0.6388 - val_accuracy: 0.7519\n",
            "Epoch 21/30\n",
            "33/33 [==============================] - 14s 419ms/step - loss: 0.6616 - accuracy: 0.7166 - val_loss: 0.6348 - val_accuracy: 0.7218\n",
            "Epoch 22/30\n",
            "33/33 [==============================] - 14s 436ms/step - loss: 0.6598 - accuracy: 0.7137 - val_loss: 0.5797 - val_accuracy: 0.7594\n",
            "Epoch 23/30\n",
            "33/33 [==============================] - 14s 418ms/step - loss: 0.6748 - accuracy: 0.7002 - val_loss: 0.5813 - val_accuracy: 0.7444\n",
            "Epoch 24/30\n",
            "33/33 [==============================] - 14s 412ms/step - loss: 0.7067 - accuracy: 0.7031 - val_loss: 0.6456 - val_accuracy: 0.7218\n",
            "Epoch 25/30\n",
            "33/33 [==============================] - 14s 415ms/step - loss: 0.6346 - accuracy: 0.7321 - val_loss: 0.5866 - val_accuracy: 0.7444\n",
            "Epoch 26/30\n",
            "33/33 [==============================] - 14s 413ms/step - loss: 0.6536 - accuracy: 0.7060 - val_loss: 0.5864 - val_accuracy: 0.7293\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f407cc54d50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lenet.evaluate(x=x_train, y=y_train)\n",
        "lenet.evaluate(x=x_valid, y=y_valid)\n",
        "lenet.evaluate(x=x_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEXBD-k3QLC4",
        "outputId": "3e328c53-2273-4730-e17f-cfd490f902fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 7s 218ms/step - loss: 0.5860 - accuracy: 0.7524\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.5797 - accuracy: 0.7594\n",
            "4/4 [==============================] - 1s 217ms/step - loss: 0.5852 - accuracy: 0.7109\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5852465033531189, 0.7109375]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### L1 Regularization"
      ],
      "metadata": {
        "id": "tiPHPtbCQnPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenet = LeNet(l1_enable=True)\n",
        "es_callback = EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True)\n",
        "lenet.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ZFJcjirRQZQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), epochs=30, callbacks=[es_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8uQDmnwQdVt",
        "outputId": "c4060bdd-3d73-4683-baf1-3df273114a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "33/33 [==============================] - 13s 387ms/step - loss: 7.2656 - accuracy: 0.4894 - val_loss: 3.2531 - val_accuracy: 0.5564\n",
            "Epoch 2/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 2.4089 - accuracy: 0.5638 - val_loss: 1.8688 - val_accuracy: 0.5038\n",
            "Epoch 3/30\n",
            "33/33 [==============================] - 14s 417ms/step - loss: 1.6831 - accuracy: 0.5861 - val_loss: 1.4678 - val_accuracy: 0.5940\n",
            "Epoch 4/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 1.3946 - accuracy: 0.6151 - val_loss: 1.2694 - val_accuracy: 0.6617\n",
            "Epoch 5/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 1.2873 - accuracy: 0.6122 - val_loss: 1.2298 - val_accuracy: 0.6015\n",
            "Epoch 6/30\n",
            "33/33 [==============================] - 13s 381ms/step - loss: 1.2283 - accuracy: 0.6315 - val_loss: 1.1712 - val_accuracy: 0.6391\n",
            "Epoch 7/30\n",
            "33/33 [==============================] - 13s 382ms/step - loss: 1.2052 - accuracy: 0.6151 - val_loss: 1.1398 - val_accuracy: 0.6391\n",
            "Epoch 8/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 1.1478 - accuracy: 0.6335 - val_loss: 1.1191 - val_accuracy: 0.6165\n",
            "Epoch 9/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 1.1332 - accuracy: 0.6170 - val_loss: 1.1014 - val_accuracy: 0.6241\n",
            "Epoch 10/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 1.1149 - accuracy: 0.6296 - val_loss: 1.0366 - val_accuracy: 0.6692\n",
            "Epoch 11/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 1.0701 - accuracy: 0.6586 - val_loss: 1.0451 - val_accuracy: 0.6241\n",
            "Epoch 12/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 1.0970 - accuracy: 0.6393 - val_loss: 1.0321 - val_accuracy: 0.6466\n",
            "Epoch 13/30\n",
            "33/33 [==============================] - 13s 382ms/step - loss: 1.1009 - accuracy: 0.6306 - val_loss: 1.0978 - val_accuracy: 0.6541\n",
            "Epoch 14/30\n",
            "33/33 [==============================] - 13s 382ms/step - loss: 1.0778 - accuracy: 0.6470 - val_loss: 1.0136 - val_accuracy: 0.6617\n",
            "Epoch 15/30\n",
            "33/33 [==============================] - 13s 381ms/step - loss: 1.0725 - accuracy: 0.6451 - val_loss: 1.0109 - val_accuracy: 0.6466\n",
            "Epoch 16/30\n",
            "33/33 [==============================] - 13s 382ms/step - loss: 1.0594 - accuracy: 0.6470 - val_loss: 0.9963 - val_accuracy: 0.6842\n",
            "Epoch 17/30\n",
            "33/33 [==============================] - 13s 382ms/step - loss: 1.0689 - accuracy: 0.6402 - val_loss: 1.0399 - val_accuracy: 0.6767\n",
            "Epoch 18/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 1.0719 - accuracy: 0.6422 - val_loss: 1.0031 - val_accuracy: 0.6767\n",
            "Epoch 19/30\n",
            "33/33 [==============================] - 13s 380ms/step - loss: 1.0570 - accuracy: 0.6364 - val_loss: 0.9954 - val_accuracy: 0.6466\n",
            "Epoch 20/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 1.0308 - accuracy: 0.6431 - val_loss: 0.9720 - val_accuracy: 0.6316\n",
            "Epoch 21/30\n",
            "33/33 [==============================] - 13s 382ms/step - loss: 1.0208 - accuracy: 0.6528 - val_loss: 1.0022 - val_accuracy: 0.6541\n",
            "Epoch 22/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 1.0812 - accuracy: 0.6248 - val_loss: 1.0293 - val_accuracy: 0.6541\n",
            "Epoch 23/30\n",
            "33/33 [==============================] - 13s 382ms/step - loss: 1.0300 - accuracy: 0.6605 - val_loss: 0.9867 - val_accuracy: 0.6241\n",
            "Epoch 24/30\n",
            "33/33 [==============================] - 13s 382ms/step - loss: 1.0151 - accuracy: 0.6489 - val_loss: 0.9518 - val_accuracy: 0.6466\n",
            "Epoch 25/30\n",
            "33/33 [==============================] - 13s 381ms/step - loss: 1.0078 - accuracy: 0.6489 - val_loss: 0.9852 - val_accuracy: 0.6541\n",
            "Epoch 26/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 0.9974 - accuracy: 0.6499 - val_loss: 0.9535 - val_accuracy: 0.6391\n",
            "Epoch 27/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.9845 - accuracy: 0.6499 - val_loss: 0.9580 - val_accuracy: 0.6842\n",
            "Epoch 28/30\n",
            "33/33 [==============================] - 13s 381ms/step - loss: 0.9925 - accuracy: 0.6460 - val_loss: 0.9548 - val_accuracy: 0.6767\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f407c973390>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lenet.evaluate(x=x_train, y=y_train)\n",
        "lenet.evaluate(x=x_valid, y=y_valid)\n",
        "lenet.evaluate(x=x_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc7x0qLZQedh",
        "outputId": "4fee7a2e-32a0-4af1-f5ca-644c036134ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 7s 219ms/step - loss: 0.9985 - accuracy: 0.6460\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.9518 - accuracy: 0.6466\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.9490 - accuracy: 0.6484\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9490329027175903, 0.6484375]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### L2 Regularization"
      ],
      "metadata": {
        "id": "KcPCPv8SQq-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenet = LeNet(l2_enable=True)\n",
        "es_callback = EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True)\n",
        "lenet.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "fAURBuO1QgSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), epochs=30, callbacks=[es_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hah0qSDQQiSO",
        "outputId": "df2724e3-81ea-4945-a5e4-45935921cb09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "33/33 [==============================] - 13s 389ms/step - loss: 1.2680 - accuracy: 0.5000 - val_loss: 1.0991 - val_accuracy: 0.5940\n",
            "Epoch 2/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 1.0111 - accuracy: 0.6431 - val_loss: 0.9281 - val_accuracy: 0.6391\n",
            "Epoch 3/30\n",
            "33/33 [==============================] - 13s 382ms/step - loss: 0.9348 - accuracy: 0.6654 - val_loss: 0.8840 - val_accuracy: 0.6466\n",
            "Epoch 4/30\n",
            "33/33 [==============================] - 13s 382ms/step - loss: 0.9021 - accuracy: 0.6702 - val_loss: 0.8489 - val_accuracy: 0.6992\n",
            "Epoch 5/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 0.8768 - accuracy: 0.6789 - val_loss: 0.8689 - val_accuracy: 0.7068\n",
            "Epoch 6/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 0.8787 - accuracy: 0.6576 - val_loss: 0.8474 - val_accuracy: 0.6391\n",
            "Epoch 7/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.8494 - accuracy: 0.6799 - val_loss: 0.8233 - val_accuracy: 0.6992\n",
            "Epoch 8/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.8713 - accuracy: 0.6576 - val_loss: 0.8428 - val_accuracy: 0.6466\n",
            "Epoch 9/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.8445 - accuracy: 0.6818 - val_loss: 0.8924 - val_accuracy: 0.6015\n",
            "Epoch 10/30\n",
            "33/33 [==============================] - 13s 385ms/step - loss: 0.8236 - accuracy: 0.6673 - val_loss: 0.8485 - val_accuracy: 0.6842\n",
            "Epoch 11/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 0.8240 - accuracy: 0.6905 - val_loss: 0.8484 - val_accuracy: 0.6917\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f407c637510>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lenet.evaluate(x=x_train, y=y_train)\n",
        "lenet.evaluate(x=x_valid, y=y_valid)\n",
        "lenet.evaluate(x=x_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBQKRHdCQk5O",
        "outputId": "3c3dd8d2-5689-442f-dc0a-7c5d94ae35e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 7s 216ms/step - loss: 0.8206 - accuracy: 0.6818\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.8233 - accuracy: 0.6992\n",
            "4/4 [==============================] - 1s 219ms/step - loss: 0.7910 - accuracy: 0.6797\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7909947037696838, 0.6796875]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kernel Size Effect"
      ],
      "metadata": {
        "id": "XjaZf_08RENI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for kernel_size in [5, 7, 9]:\n",
        "  print(f\"kernel size = {kernel_size}\")\n",
        "  lenet = LeNet(kernel_size=kernel_size)\n",
        "  es_callback = EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True)\n",
        "  lenet.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  lenet.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), epochs=30, callbacks=[es_callback])\n",
        "\n",
        "  lenet.evaluate(x=x_train, y=y_train)\n",
        "  lenet.evaluate(x=x_valid, y=y_valid)\n",
        "  lenet.evaluate(x=x_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUMQQgTBRX6v",
        "outputId": "a12da2d7-56b8-4062-e1cd-1d39c49b1ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kernel size = 5\n",
            "Epoch 1/30\n",
            "33/33 [==============================] - 13s 385ms/step - loss: 0.9760 - accuracy: 0.4913 - val_loss: 0.7929 - val_accuracy: 0.6015\n",
            "Epoch 2/30\n",
            "33/33 [==============================] - 13s 380ms/step - loss: 0.8182 - accuracy: 0.5996 - val_loss: 0.7611 - val_accuracy: 0.6617\n",
            "Epoch 3/30\n",
            "33/33 [==============================] - 12s 379ms/step - loss: 0.7611 - accuracy: 0.6596 - val_loss: 0.7812 - val_accuracy: 0.6992\n",
            "Epoch 4/30\n",
            "33/33 [==============================] - 12s 378ms/step - loss: 0.7456 - accuracy: 0.6518 - val_loss: 0.6878 - val_accuracy: 0.7068\n",
            "Epoch 5/30\n",
            "33/33 [==============================] - 13s 380ms/step - loss: 0.7325 - accuracy: 0.6702 - val_loss: 0.6722 - val_accuracy: 0.6992\n",
            "Epoch 6/30\n",
            "33/33 [==============================] - 12s 378ms/step - loss: 0.7154 - accuracy: 0.6809 - val_loss: 0.6972 - val_accuracy: 0.6917\n",
            "Epoch 7/30\n",
            "33/33 [==============================] - 12s 379ms/step - loss: 0.6870 - accuracy: 0.7021 - val_loss: 0.6652 - val_accuracy: 0.7143\n",
            "Epoch 8/30\n",
            "33/33 [==============================] - 12s 379ms/step - loss: 0.6540 - accuracy: 0.7021 - val_loss: 0.6796 - val_accuracy: 0.6917\n",
            "Epoch 9/30\n",
            "33/33 [==============================] - 13s 380ms/step - loss: 0.6578 - accuracy: 0.7186 - val_loss: 0.6509 - val_accuracy: 0.6617\n",
            "Epoch 10/30\n",
            "33/33 [==============================] - 13s 381ms/step - loss: 0.6673 - accuracy: 0.7118 - val_loss: 0.8339 - val_accuracy: 0.6241\n",
            "Epoch 11/30\n",
            "33/33 [==============================] - 12s 379ms/step - loss: 0.7006 - accuracy: 0.6963 - val_loss: 0.6629 - val_accuracy: 0.6767\n",
            "Epoch 12/30\n",
            "33/33 [==============================] - 13s 381ms/step - loss: 0.6290 - accuracy: 0.7311 - val_loss: 0.6235 - val_accuracy: 0.7068\n",
            "Epoch 13/30\n",
            "33/33 [==============================] - 12s 379ms/step - loss: 0.6273 - accuracy: 0.7215 - val_loss: 0.6620 - val_accuracy: 0.6842\n",
            "Epoch 14/30\n",
            "33/33 [==============================] - 13s 380ms/step - loss: 0.6005 - accuracy: 0.7408 - val_loss: 0.6701 - val_accuracy: 0.7068\n",
            "Epoch 15/30\n",
            "33/33 [==============================] - 13s 382ms/step - loss: 0.6425 - accuracy: 0.7108 - val_loss: 0.6705 - val_accuracy: 0.6992\n",
            "Epoch 16/30\n",
            "33/33 [==============================] - 13s 381ms/step - loss: 0.6431 - accuracy: 0.7224 - val_loss: 0.6348 - val_accuracy: 0.6917\n",
            "33/33 [==============================] - 7s 215ms/step - loss: 0.5875 - accuracy: 0.7485\n",
            "5/5 [==============================] - 1s 174ms/step - loss: 0.6235 - accuracy: 0.7068\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 0.6660 - accuracy: 0.7031\n",
            "kernel size = 7\n",
            "Epoch 1/30\n",
            "33/33 [==============================] - 19s 561ms/step - loss: 1.1329 - accuracy: 0.3559 - val_loss: 1.0048 - val_accuracy: 0.5639\n",
            "Epoch 2/30\n",
            "33/33 [==============================] - 18s 559ms/step - loss: 0.9649 - accuracy: 0.5126 - val_loss: 0.8723 - val_accuracy: 0.5865\n",
            "Epoch 3/30\n",
            "33/33 [==============================] - 18s 557ms/step - loss: 0.8346 - accuracy: 0.5967 - val_loss: 0.7942 - val_accuracy: 0.6015\n",
            "Epoch 4/30\n",
            "33/33 [==============================] - 18s 553ms/step - loss: 0.7665 - accuracy: 0.6480 - val_loss: 0.7413 - val_accuracy: 0.5865\n",
            "Epoch 5/30\n",
            "33/33 [==============================] - 18s 554ms/step - loss: 0.7445 - accuracy: 0.6586 - val_loss: 0.7252 - val_accuracy: 0.6767\n",
            "Epoch 6/30\n",
            "33/33 [==============================] - 18s 555ms/step - loss: 0.7510 - accuracy: 0.6702 - val_loss: 0.7288 - val_accuracy: 0.6617\n",
            "Epoch 7/30\n",
            "33/33 [==============================] - 18s 555ms/step - loss: 0.7425 - accuracy: 0.6644 - val_loss: 0.6914 - val_accuracy: 0.6617\n",
            "Epoch 8/30\n",
            "33/33 [==============================] - 18s 556ms/step - loss: 0.7135 - accuracy: 0.6741 - val_loss: 0.7509 - val_accuracy: 0.6692\n",
            "Epoch 9/30\n",
            "33/33 [==============================] - 18s 554ms/step - loss: 0.7447 - accuracy: 0.6567 - val_loss: 0.7025 - val_accuracy: 0.6466\n",
            "Epoch 10/30\n",
            "33/33 [==============================] - 18s 556ms/step - loss: 0.7292 - accuracy: 0.6644 - val_loss: 0.7473 - val_accuracy: 0.6316\n",
            "Epoch 11/30\n",
            "33/33 [==============================] - 18s 557ms/step - loss: 0.7018 - accuracy: 0.6760 - val_loss: 0.7144 - val_accuracy: 0.6617\n",
            "33/33 [==============================] - 9s 282ms/step - loss: 0.6994 - accuracy: 0.6847\n",
            "5/5 [==============================] - 1s 225ms/step - loss: 0.6914 - accuracy: 0.6617\n",
            "4/4 [==============================] - 1s 286ms/step - loss: 0.6855 - accuracy: 0.7031\n",
            "kernel size = 9\n",
            "Epoch 1/30\n",
            "33/33 [==============================] - 29s 880ms/step - loss: 0.9452 - accuracy: 0.5222 - val_loss: 0.7971 - val_accuracy: 0.6015\n",
            "Epoch 2/30\n",
            "33/33 [==============================] - 29s 878ms/step - loss: 0.8381 - accuracy: 0.5996 - val_loss: 0.7891 - val_accuracy: 0.6165\n",
            "Epoch 3/30\n",
            "33/33 [==============================] - 29s 880ms/step - loss: 0.7734 - accuracy: 0.6373 - val_loss: 1.1259 - val_accuracy: 0.5038\n",
            "Epoch 4/30\n",
            "33/33 [==============================] - 29s 876ms/step - loss: 0.7834 - accuracy: 0.6306 - val_loss: 0.6895 - val_accuracy: 0.6767\n",
            "Epoch 5/30\n",
            "33/33 [==============================] - 29s 878ms/step - loss: 0.7180 - accuracy: 0.6847 - val_loss: 0.7422 - val_accuracy: 0.6316\n",
            "Epoch 6/30\n",
            "33/33 [==============================] - 29s 875ms/step - loss: 0.7257 - accuracy: 0.6605 - val_loss: 0.7451 - val_accuracy: 0.6917\n",
            "Epoch 7/30\n",
            "33/33 [==============================] - 29s 877ms/step - loss: 0.7331 - accuracy: 0.6644 - val_loss: 0.7713 - val_accuracy: 0.6541\n",
            "Epoch 8/30\n",
            "33/33 [==============================] - 29s 880ms/step - loss: 0.7169 - accuracy: 0.6605 - val_loss: 0.7077 - val_accuracy: 0.6917\n",
            "33/33 [==============================] - 11s 337ms/step - loss: 0.6913 - accuracy: 0.6857\n",
            "5/5 [==============================] - 1s 269ms/step - loss: 0.6895 - accuracy: 0.6767\n",
            "4/4 [==============================] - 2s 344ms/step - loss: 0.6725 - accuracy: 0.6562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kernel Number Effect"
      ],
      "metadata": {
        "id": "_GS7LTfZRvuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for kernel_numbers in [\n",
        "                       [3, 10, 40],\n",
        "                       [6, 16, 120],\n",
        "                       [10, 40, 300]]:\n",
        "\n",
        "  print(f\"kernel numbers = {kernel_numbers}\")\n",
        "  lenet = LeNet(kernel_numbers=kernel_numbers)\n",
        "  es_callback = EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True)\n",
        "  lenet.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  lenet.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), epochs=30, callbacks=[es_callback])\n",
        "\n",
        "  lenet.evaluate(x=x_train, y=y_train)\n",
        "  lenet.evaluate(x=x_valid, y=y_valid)\n",
        "  lenet.evaluate(x=x_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjE5racrRvFD",
        "outputId": "2aab017a-2fb7-47d2-8a4b-9d0945b28c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kernel numbers = [3, 10, 40]\n",
            "Epoch 1/30\n",
            "33/33 [==============================] - 14s 425ms/step - loss: 1.0414 - accuracy: 0.4594 - val_loss: 0.8754 - val_accuracy: 0.5865\n",
            "Epoch 2/30\n",
            "33/33 [==============================] - 12s 371ms/step - loss: 0.8532 - accuracy: 0.5948 - val_loss: 0.7496 - val_accuracy: 0.6617\n",
            "Epoch 3/30\n",
            "33/33 [==============================] - 12s 371ms/step - loss: 0.7816 - accuracy: 0.6518 - val_loss: 0.7181 - val_accuracy: 0.6692\n",
            "Epoch 4/30\n",
            "33/33 [==============================] - 12s 370ms/step - loss: 0.7376 - accuracy: 0.6673 - val_loss: 0.7553 - val_accuracy: 0.6391\n",
            "Epoch 5/30\n",
            "33/33 [==============================] - 12s 372ms/step - loss: 0.7968 - accuracy: 0.6364 - val_loss: 0.7713 - val_accuracy: 0.6241\n",
            "Epoch 6/30\n",
            "33/33 [==============================] - 12s 373ms/step - loss: 0.7783 - accuracy: 0.6518 - val_loss: 0.7504 - val_accuracy: 0.6090\n",
            "Epoch 7/30\n",
            "33/33 [==============================] - 12s 370ms/step - loss: 0.7623 - accuracy: 0.6528 - val_loss: 0.7288 - val_accuracy: 0.6316\n",
            "33/33 [==============================] - 7s 208ms/step - loss: 0.7363 - accuracy: 0.6750\n",
            "5/5 [==============================] - 1s 169ms/step - loss: 0.7181 - accuracy: 0.6692\n",
            "4/4 [==============================] - 1s 210ms/step - loss: 0.7145 - accuracy: 0.6953\n",
            "kernel numbers = [6, 16, 120]\n",
            "Epoch 1/30\n",
            "33/33 [==============================] - 14s 395ms/step - loss: 1.0472 - accuracy: 0.4439 - val_loss: 0.8960 - val_accuracy: 0.6165\n",
            "Epoch 2/30\n",
            "33/33 [==============================] - 13s 390ms/step - loss: 0.8565 - accuracy: 0.6025 - val_loss: 0.7515 - val_accuracy: 0.7218\n",
            "Epoch 3/30\n",
            "33/33 [==============================] - 13s 391ms/step - loss: 0.7784 - accuracy: 0.6480 - val_loss: 0.7349 - val_accuracy: 0.6842\n",
            "Epoch 4/30\n",
            "33/33 [==============================] - 13s 390ms/step - loss: 0.7648 - accuracy: 0.6809 - val_loss: 0.7724 - val_accuracy: 0.6842\n",
            "Epoch 5/30\n",
            "33/33 [==============================] - 13s 390ms/step - loss: 0.7979 - accuracy: 0.6460 - val_loss: 0.7552 - val_accuracy: 0.6391\n",
            "Epoch 6/30\n",
            "33/33 [==============================] - 13s 400ms/step - loss: 0.7335 - accuracy: 0.6857 - val_loss: 0.7149 - val_accuracy: 0.6992\n",
            "Epoch 7/30\n",
            "33/33 [==============================] - 13s 389ms/step - loss: 0.7294 - accuracy: 0.6731 - val_loss: 0.6902 - val_accuracy: 0.6466\n",
            "Epoch 8/30\n",
            "33/33 [==============================] - 13s 391ms/step - loss: 0.7213 - accuracy: 0.6847 - val_loss: 0.7107 - val_accuracy: 0.6917\n",
            "Epoch 9/30\n",
            "33/33 [==============================] - 13s 389ms/step - loss: 0.7385 - accuracy: 0.6847 - val_loss: 0.6926 - val_accuracy: 0.7068\n",
            "Epoch 10/30\n",
            "33/33 [==============================] - 13s 389ms/step - loss: 0.7197 - accuracy: 0.6934 - val_loss: 0.7328 - val_accuracy: 0.6692\n",
            "Epoch 11/30\n",
            "33/33 [==============================] - 13s 389ms/step - loss: 0.6969 - accuracy: 0.6905 - val_loss: 0.6586 - val_accuracy: 0.7218\n",
            "Epoch 12/30\n",
            "33/33 [==============================] - 13s 391ms/step - loss: 0.6818 - accuracy: 0.6925 - val_loss: 0.7217 - val_accuracy: 0.6391\n",
            "Epoch 13/30\n",
            "33/33 [==============================] - 13s 391ms/step - loss: 0.6686 - accuracy: 0.7089 - val_loss: 0.6549 - val_accuracy: 0.7444\n",
            "Epoch 14/30\n",
            "33/33 [==============================] - 13s 391ms/step - loss: 0.6851 - accuracy: 0.6973 - val_loss: 0.6555 - val_accuracy: 0.7519\n",
            "Epoch 15/30\n",
            "33/33 [==============================] - 13s 389ms/step - loss: 0.6536 - accuracy: 0.7215 - val_loss: 0.6260 - val_accuracy: 0.7218\n",
            "Epoch 16/30\n",
            "33/33 [==============================] - 13s 391ms/step - loss: 0.6671 - accuracy: 0.7118 - val_loss: 0.7540 - val_accuracy: 0.6241\n",
            "Epoch 17/30\n",
            "33/33 [==============================] - 13s 390ms/step - loss: 0.6864 - accuracy: 0.7002 - val_loss: 0.6896 - val_accuracy: 0.6917\n",
            "Epoch 18/30\n",
            "33/33 [==============================] - 13s 389ms/step - loss: 0.6350 - accuracy: 0.7263 - val_loss: 0.6548 - val_accuracy: 0.6917\n",
            "Epoch 19/30\n",
            "33/33 [==============================] - 13s 390ms/step - loss: 0.6260 - accuracy: 0.7273 - val_loss: 0.6320 - val_accuracy: 0.6992\n",
            "33/33 [==============================] - 7s 221ms/step - loss: 0.6273 - accuracy: 0.7234\n",
            "5/5 [==============================] - 1s 172ms/step - loss: 0.6260 - accuracy: 0.7218\n",
            "4/4 [==============================] - 1s 222ms/step - loss: 0.6434 - accuracy: 0.6797\n",
            "kernel numbers = [10, 40, 300]\n",
            "Epoch 1/30\n",
            "33/33 [==============================] - 12s 335ms/step - loss: 0.9117 - accuracy: 0.5832 - val_loss: 0.9614 - val_accuracy: 0.5263\n",
            "Epoch 2/30\n",
            "33/33 [==============================] - 11s 330ms/step - loss: 0.8558 - accuracy: 0.5967 - val_loss: 0.7750 - val_accuracy: 0.6165\n",
            "Epoch 3/30\n",
            "33/33 [==============================] - 11s 331ms/step - loss: 0.8103 - accuracy: 0.6344 - val_loss: 0.7728 - val_accuracy: 0.6842\n",
            "Epoch 4/30\n",
            "33/33 [==============================] - 11s 330ms/step - loss: 0.7891 - accuracy: 0.6412 - val_loss: 0.7537 - val_accuracy: 0.7293\n",
            "Epoch 5/30\n",
            "33/33 [==============================] - 11s 330ms/step - loss: 0.7253 - accuracy: 0.6818 - val_loss: 0.6759 - val_accuracy: 0.6842\n",
            "Epoch 6/30\n",
            "33/33 [==============================] - 11s 330ms/step - loss: 0.7598 - accuracy: 0.6721 - val_loss: 0.6933 - val_accuracy: 0.6917\n",
            "Epoch 7/30\n",
            "33/33 [==============================] - 11s 331ms/step - loss: 0.7261 - accuracy: 0.6615 - val_loss: 0.7076 - val_accuracy: 0.6541\n",
            "Epoch 8/30\n",
            "33/33 [==============================] - 11s 331ms/step - loss: 0.6817 - accuracy: 0.6963 - val_loss: 0.6075 - val_accuracy: 0.7218\n",
            "Epoch 9/30\n",
            "33/33 [==============================] - 11s 330ms/step - loss: 0.6826 - accuracy: 0.7060 - val_loss: 0.6073 - val_accuracy: 0.7444\n",
            "Epoch 10/30\n",
            "33/33 [==============================] - 11s 331ms/step - loss: 0.6418 - accuracy: 0.7176 - val_loss: 0.6439 - val_accuracy: 0.6617\n",
            "Epoch 11/30\n",
            "33/33 [==============================] - 11s 330ms/step - loss: 0.6280 - accuracy: 0.7215 - val_loss: 0.6406 - val_accuracy: 0.7368\n",
            "Epoch 12/30\n",
            "33/33 [==============================] - 11s 332ms/step - loss: 0.5868 - accuracy: 0.7340 - val_loss: 0.5721 - val_accuracy: 0.7669\n",
            "Epoch 13/30\n",
            "33/33 [==============================] - 11s 331ms/step - loss: 0.5474 - accuracy: 0.7631 - val_loss: 0.7272 - val_accuracy: 0.6842\n",
            "Epoch 14/30\n",
            "33/33 [==============================] - 11s 331ms/step - loss: 0.5898 - accuracy: 0.7331 - val_loss: 0.6265 - val_accuracy: 0.7669\n",
            "Epoch 15/30\n",
            "33/33 [==============================] - 11s 331ms/step - loss: 0.5566 - accuracy: 0.7602 - val_loss: 0.5609 - val_accuracy: 0.7970\n",
            "Epoch 16/30\n",
            "33/33 [==============================] - 11s 330ms/step - loss: 0.5234 - accuracy: 0.7689 - val_loss: 0.5827 - val_accuracy: 0.7293\n",
            "Epoch 17/30\n",
            "33/33 [==============================] - 11s 332ms/step - loss: 0.5034 - accuracy: 0.7901 - val_loss: 0.6350 - val_accuracy: 0.6842\n",
            "Epoch 18/30\n",
            "33/33 [==============================] - 11s 331ms/step - loss: 0.4989 - accuracy: 0.7824 - val_loss: 0.5722 - val_accuracy: 0.7444\n",
            "Epoch 19/30\n",
            "33/33 [==============================] - 11s 331ms/step - loss: 0.4596 - accuracy: 0.8133 - val_loss: 0.6073 - val_accuracy: 0.7143\n",
            "33/33 [==============================] - 5s 142ms/step - loss: 0.4716 - accuracy: 0.8037\n",
            "5/5 [==============================] - 1s 113ms/step - loss: 0.5609 - accuracy: 0.7970\n",
            "4/4 [==============================] - 1s 141ms/step - loss: 0.5447 - accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Setting"
      ],
      "metadata": {
        "id": "k1Qyxzv9uqwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Om38hL9-wXDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet = LeNet(kernel_size=5, kernel_numbers=[10, 40, 300], dropout_enable=True)\n",
        "es_callback = EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True)\n",
        "lenet.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "es_callback = EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True)\n",
        "lenet.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "lenet.fit(x=x_train, y=y_train, validation_data=(x_valid, y_valid), epochs=30, callbacks=[es_callback])\n",
        "\n",
        "lenet.evaluate(x=x_train, y=y_train)\n",
        "lenet.evaluate(x=x_valid, y=y_valid)\n",
        "lenet.evaluate(x=x_test, y=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVHY4o09SXib",
        "outputId": "18d9676c-426d-41d5-9ad6-51264cf0672f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "33/33 [==============================] - 14s 399ms/step - loss: 0.9390 - accuracy: 0.5532 - val_loss: 0.7473 - val_accuracy: 0.7068\n",
            "Epoch 2/30\n",
            "33/33 [==============================] - 13s 385ms/step - loss: 0.7935 - accuracy: 0.6499 - val_loss: 0.7326 - val_accuracy: 0.6617\n",
            "Epoch 3/30\n",
            "33/33 [==============================] - 13s 387ms/step - loss: 0.7805 - accuracy: 0.6489 - val_loss: 0.6819 - val_accuracy: 0.6767\n",
            "Epoch 4/30\n",
            "33/33 [==============================] - 13s 385ms/step - loss: 0.7824 - accuracy: 0.6480 - val_loss: 0.6740 - val_accuracy: 0.6992\n",
            "Epoch 5/30\n",
            "33/33 [==============================] - 13s 391ms/step - loss: 0.8019 - accuracy: 0.6267 - val_loss: 0.6795 - val_accuracy: 0.6992\n",
            "Epoch 6/30\n",
            "33/33 [==============================] - 13s 385ms/step - loss: 0.7306 - accuracy: 0.6712 - val_loss: 0.6887 - val_accuracy: 0.6842\n",
            "Epoch 7/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.7360 - accuracy: 0.6750 - val_loss: 0.6622 - val_accuracy: 0.6917\n",
            "Epoch 8/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.7608 - accuracy: 0.6557 - val_loss: 0.7284 - val_accuracy: 0.6842\n",
            "Epoch 9/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.7151 - accuracy: 0.6905 - val_loss: 0.7238 - val_accuracy: 0.7068\n",
            "Epoch 10/30\n",
            "33/33 [==============================] - 13s 398ms/step - loss: 0.7394 - accuracy: 0.6596 - val_loss: 0.6100 - val_accuracy: 0.7218\n",
            "Epoch 11/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.7164 - accuracy: 0.6789 - val_loss: 0.6423 - val_accuracy: 0.7293\n",
            "Epoch 12/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 0.6776 - accuracy: 0.6973 - val_loss: 0.6481 - val_accuracy: 0.6692\n",
            "Epoch 13/30\n",
            "33/33 [==============================] - 13s 381ms/step - loss: 0.6843 - accuracy: 0.7079 - val_loss: 0.6802 - val_accuracy: 0.7068\n",
            "Epoch 14/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.6770 - accuracy: 0.6876 - val_loss: 0.6030 - val_accuracy: 0.7444\n",
            "Epoch 15/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.6693 - accuracy: 0.6963 - val_loss: 0.7455 - val_accuracy: 0.6992\n",
            "Epoch 16/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 0.7013 - accuracy: 0.7050 - val_loss: 0.7035 - val_accuracy: 0.6541\n",
            "Epoch 17/30\n",
            "33/33 [==============================] - 13s 382ms/step - loss: 0.6812 - accuracy: 0.6925 - val_loss: 0.5873 - val_accuracy: 0.7218\n",
            "Epoch 18/30\n",
            "33/33 [==============================] - 13s 383ms/step - loss: 0.6605 - accuracy: 0.6954 - val_loss: 0.6641 - val_accuracy: 0.6992\n",
            "Epoch 19/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.6698 - accuracy: 0.7041 - val_loss: 0.6176 - val_accuracy: 0.7068\n",
            "Epoch 20/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.6101 - accuracy: 0.7369 - val_loss: 0.5840 - val_accuracy: 0.7293\n",
            "Epoch 21/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.6056 - accuracy: 0.7205 - val_loss: 0.5919 - val_accuracy: 0.7368\n",
            "Epoch 22/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.5697 - accuracy: 0.7640 - val_loss: 0.5427 - val_accuracy: 0.7519\n",
            "Epoch 23/30\n",
            "33/33 [==============================] - 13s 386ms/step - loss: 0.5922 - accuracy: 0.7544 - val_loss: 0.5534 - val_accuracy: 0.7669\n",
            "Epoch 24/30\n",
            "33/33 [==============================] - 13s 386ms/step - loss: 0.5850 - accuracy: 0.7466 - val_loss: 0.5263 - val_accuracy: 0.7669\n",
            "Epoch 25/30\n",
            "33/33 [==============================] - 13s 385ms/step - loss: 0.5948 - accuracy: 0.7505 - val_loss: 0.5857 - val_accuracy: 0.7218\n",
            "Epoch 26/30\n",
            "33/33 [==============================] - 13s 386ms/step - loss: 0.5744 - accuracy: 0.7553 - val_loss: 0.5960 - val_accuracy: 0.7368\n",
            "Epoch 27/30\n",
            "33/33 [==============================] - 13s 384ms/step - loss: 0.5584 - accuracy: 0.7640 - val_loss: 0.5095 - val_accuracy: 0.8045\n",
            "Epoch 28/30\n",
            "33/33 [==============================] - 13s 386ms/step - loss: 0.5346 - accuracy: 0.7669 - val_loss: 0.6302 - val_accuracy: 0.7293\n",
            "Epoch 29/30\n",
            "33/33 [==============================] - 13s 385ms/step - loss: 0.5367 - accuracy: 0.7708 - val_loss: 0.4941 - val_accuracy: 0.7669\n",
            "Epoch 30/30\n",
            "33/33 [==============================] - 13s 385ms/step - loss: 0.5181 - accuracy: 0.7805 - val_loss: 0.5585 - val_accuracy: 0.7218\n",
            "33/33 [==============================] - 5s 141ms/step - loss: 0.4847 - accuracy: 0.7921\n",
            "5/5 [==============================] - 1s 114ms/step - loss: 0.5585 - accuracy: 0.7218\n",
            "4/4 [==============================] - 1s 146ms/step - loss: 0.5686 - accuracy: 0.7578\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5686240792274475, 0.7578125]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inception"
      ],
      "metadata": {
        "id": "j0RUuLHZVUg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtZM2-ogwVj4",
        "outputId": "48cfc902-0c2e-4b3b-f7a0-34f9ac13cf42"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1034, 500, 500, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = InceptionV3(input_shape=(500, 500, 3), include_top=False, weights='imagenet')"
      ],
      "metadata": {
        "id": "ldCx7yNUv3Q_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o_base_model = base_model(x_train[:100])"
      ],
      "metadata": {
        "id": "oHNRP6_axTLW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o_base_model.numpy().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlAZ-eZRSmOq",
        "outputId": "dd7d2f55-8187-4941-f6d8-f2aff37f4982"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 14, 14, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "biTxOoUTTGoi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(base_model.layers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMPKdGAdYfBw",
        "outputId": "6464a4d9-698d-4a43-f8f2-b8cabcc14cb6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "311"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnN1iPmPUiEQ",
        "outputId": "35b59924-ddf9-496f-8fb6-abe15d501620"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 500, 500, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 249, 249, 32  864         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 249, 249, 32  96         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 249, 249, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 247, 247, 32  9216        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 247, 247, 32  96         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 247, 247, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 247, 247, 64  18432       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 247, 247, 64  192        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 247, 247, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 123, 123, 64  0           ['activation_2[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 123, 123, 80  5120        ['max_pooling2d[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 123, 123, 80  240        ['conv2d_3[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 123, 123, 80  0           ['batch_normalization_3[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 121, 121, 19  138240      ['activation_3[0][0]']           \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 121, 121, 19  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                   2)                                                                \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 121, 121, 19  0           ['batch_normalization_4[0][0]']  \n",
            "                                2)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 60, 60, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 60, 60, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 60, 60, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 60, 60, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 60, 60, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 60, 60, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 60, 60, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 60, 60, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 60, 60, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 60, 60, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 60, 60, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 60, 60, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 60, 60, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 60, 60, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 60, 60, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 60, 60, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 60, 60, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 60, 60, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 60, 60, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 60, 60, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 60, 60, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 60, 60, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 60, 60, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 60, 60, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 60, 60, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 60, 60, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 60, 60, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 60, 60, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 60, 60, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 60, 60, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 60, 60, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 60, 60, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 60, 60, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 60, 60, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 60, 60, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 60, 60, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 60, 60, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 60, 60, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 60, 60, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 60, 60, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 60, 60, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 60, 60, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 60, 60, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 60, 60, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 60, 60, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 60, 60, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 60, 60, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 60, 60, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 60, 60, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 60, 60, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 60, 60, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 60, 60, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 60, 60, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 60, 60, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 60, 60, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 60, 60, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 60, 60, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 60, 60, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 60, 60, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 60, 60, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 60, 60, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 60, 60, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 60, 60, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 60, 60, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 60, 60, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 60, 60, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 60, 60, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 60, 60, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 60, 60, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 60, 60, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 60, 60, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 60, 60, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 60, 60, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 60, 60, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 60, 60, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 60, 60, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 29, 29, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 29, 29, 96)   82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 29, 29, 384)  1152       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 29, 29, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 29, 29, 384)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 29, 29, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 29, 29, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 29, 29, 768)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 29, 29, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 29, 29, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 29, 29, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 29, 29, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 29, 29, 128)  384        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 29, 29, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 29, 29, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 29, 29, 128)  114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 29, 29, 128)  384        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 29, 29, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 29, 29, 128)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 29, 29, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 29, 29, 128)  114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 29, 29, 128)  114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 29, 29, 128)  384        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 29, 29, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 29, 29, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 29, 29, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 29, 29, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 29, 29, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 29, 29, 192)  172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 29, 29, 192)  172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 29, 29, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 29, 29, 192)  576        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 29, 29, 192)  576        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 29, 29, 192)  576        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 29, 29, 192)  576        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 29, 29, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 29, 29, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 29, 29, 160)  480        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 29, 29, 160)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 29, 29, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 29, 29, 160)  480        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 29, 29, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 29, 29, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 29, 29, 160)  179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 29, 29, 160)  480        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 29, 29, 160)  480        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 29, 29, 160)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 29, 29, 160)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 29, 29, 160)  179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 29, 29, 160)  179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 29, 29, 160)  480        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 29, 29, 160)  480        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 29, 29, 160)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 29, 29, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 29, 29, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 29, 29, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 29, 29, 192)  215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 29, 29, 192)  215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 29, 29, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 29, 29, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 29, 29, 192)  576        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 29, 29, 192)  576        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 29, 29, 192)  576        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 29, 29, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 29, 29, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 29, 29, 160)  480        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 29, 29, 160)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 29, 29, 160)  179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 29, 29, 160)  480        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 29, 29, 160)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 29, 29, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 29, 29, 160)  179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 29, 29, 160)  480        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 29, 29, 160)  480        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 29, 29, 160)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 29, 29, 160)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 29, 29, 160)  179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 29, 29, 160)  179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 29, 29, 160)  480        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 29, 29, 160)  480        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 29, 29, 160)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 29, 29, 160)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 29, 29, 768)  0          ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 29, 29, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 29, 29, 192)  215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 29, 29, 192)  215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 29, 29, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 29, 29, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 29, 29, 192)  576        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 29, 29, 192)  576        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 29, 29, 192)  576        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 29, 29, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 29, 29, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 29, 29, 192)  576        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 29, 29, 192)  258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 29, 29, 192)  576        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 29, 29, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 29, 29, 192)  258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 29, 29, 192)  576        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 29, 29, 192)  576        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 29, 29, 192)  258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 29, 29, 192)  258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 29, 29, 192)  576        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 29, 29, 192)  576        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 29, 29, 768)  0          ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 29, 29, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 29, 29, 192)  258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 29, 29, 192)  258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 29, 29, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 29, 29, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 29, 29, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 29, 29, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 29, 29, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 29, 29, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 29, 29, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 29, 29, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 29, 29, 192)  258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 29, 29, 192)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 29, 29, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 29, 29, 192)  258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 29, 29, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 29, 29, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 29, 29, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 14, 14, 320)  552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 14, 14, 192)  331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 14, 14, 320)  960        ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 14, 14, 192)  576        ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 14, 14, 320)  0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 14, 14, 192)  0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 768)  0          ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 14, 14, 1280  0           ['activation_71[0][0]',          \n",
            "                                )                                 'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 14, 14, 448)  573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 14, 14, 448)  1344       ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 14, 14, 448)  0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 14, 14, 384)  491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 14, 14, 384)  1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 14, 14, 384)  1152       ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 14, 14, 384)  1152       ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 14, 14, 384)  0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 14, 14, 384)  0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 14, 14, 384)  442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 14, 14, 384)  442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 14, 14, 384)  442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 14, 14, 384)  442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 14, 14, 1280  0          ['mixed8[0][0]']                 \n",
            " oling2D)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 14, 14, 320)  409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 14, 14, 384)  1152       ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 14, 14, 384)  1152       ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 14, 14, 384)  1152       ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 14, 14, 384)  1152       ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 14, 14, 192)  245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 14, 14, 320)  960        ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 14, 14, 384)  0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 14, 14, 384)  0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 14, 14, 384)  0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 14, 14, 384)  0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 14, 14, 192)  576        ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 14, 14, 320)  0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 14, 14, 768)  0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 14, 14, 768)  0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 14, 14, 192)  0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 14, 14, 2048  0           ['activation_76[0][0]',          \n",
            "                                )                                 'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 14, 14, 448)  917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 14, 14, 448)  1344       ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 14, 14, 448)  0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 14, 14, 384)  786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 14, 14, 384)  1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 14, 14, 384)  1152       ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 14, 14, 384)  1152       ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 14, 14, 384)  0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 14, 14, 384)  0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 14, 14, 384)  442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 14, 14, 384)  442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 14, 14, 384)  442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 14, 14, 384)  442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 14, 14, 2048  0          ['mixed9[0][0]']                 \n",
            " oling2D)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 14, 14, 320)  655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 14, 14, 384)  1152       ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 14, 14, 384)  1152       ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 14, 14, 384)  1152       ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 14, 14, 384)  1152       ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 14, 14, 192)  393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 14, 14, 320)  960        ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 14, 14, 384)  0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 14, 14, 384)  0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 14, 14, 384)  0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 14, 14, 384)  0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 14, 14, 192)  576        ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 14, 14, 320)  0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 14, 14, 768)  0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 14, 14, 768)  0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 14, 14, 192)  0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 14, 14, 2048  0           ['activation_85[0][0]',          \n",
            "                                )                                 'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VPSn42nMUmLo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}